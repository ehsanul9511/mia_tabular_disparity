{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import data_utils\n",
    "import model_utils\n",
    "from attack_utils import get_CSMIA_case_by_case_results, CSMIA_attack, LOMIA_attack\n",
    "from data_utils import oneHotCatVars, filter_random_data_by_conf_score\n",
    "from vulnerability_score_utils import get_vulnerability_score, draw_hist_plot\n",
    "from experiment_utils import MIAExperiment\n",
    "from disparity_inference_utils import get_confidence_array, draw_confidence_array_scatter, get_indices_by_group_condition, get_corr_btn_sens_and_out_per_subgroup, get_slopes, get_angular_difference, calculate_stds, get_mutual_info_btn_sens_and_out_per_subgroup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network._base import ACTIVATIONS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import pickle\n",
    "# import utils\n",
    "import copy\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Setting the font family, size, and weight globally\n",
    "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "mpl.rcParams['font.size'] = 8\n",
    "mpl.rcParams['font.weight'] = 'light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "{0: {(0, 1): 8750, (0, 0): 3750, (1, 1): 3750, (1, 0): 8750}, 1: {(0, 1): 8750, (0, 0): 3750, (1, 1): 3750, (1, 0): 8750}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {(0, 1): 6875, (0, 0): 5625, (1, 1): 5625, (1, 0): 6875}, 1: {(0, 1): 7500, (0, 0): 5000, (1, 1): 5000, (1, 0): 7500}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "i = -0.4\n",
    "j = -0.4\n",
    "experiment = MIAExperiment(sampling_condition_dict = \n",
    "    {\n",
    "            'correlation': 0,\n",
    "            'subgroup_col_name': 'SEX',\n",
    "            'marginal_prior': 1,\n",
    "            'corr_btn_sens_and_output_per_subgroup': (i, j),\n",
    "            # 'fixed_corr_in_test_data': True\n",
    "    }, shortname = f\"Corr_btn_sens_and_output_for_male_({i})_for_female_({j})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(32, 16, 8), max_iter=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(32, 16, 8), max_iter=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(32, 16, 8), max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = model_utils.get_model(max_iter=500)\n",
    "experiment.clf_only_on_test = copy.deepcopy(base_model)\n",
    "experiment.clf_only_on_test.fit(experiment.X_test, experiment.y_te_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.original_df = experiment.ds.ds.original_df[experiment.ds.ds.original_df['is_train']==0]\n",
    "experiment.original_df = experiment.original_df.drop(['is_train'], axis=1)\n",
    "experiment.aux_df = experiment.ds.ds.original_df[experiment.ds.ds.original_df['is_train']==1]\n",
    "experiment.aux_df = experiment.aux_df.drop(['is_train'], axis=1)\n",
    "experiment.y_column = experiment.ds.ds.meta['y_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_pred, case_indices = CSMIA_attack(experiment.clf_only_on_test, experiment.X_test, experiment.y_te, experiment.ds.ds.meta)\n",
    "experiment.correct_indices = (sens_pred == experiment.X_test[[f'{experiment.ds.ds.meta[\"sensitive_column\"]}_1']].to_numpy().ravel())\n",
    "experiment.incorrect_indices = ~experiment.correct_indices\n",
    "experiment.sensitive_column = experiment.ds.ds.meta[\"sensitive_column\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [08:30<00:00, 98.01it/s] \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment.all_vuln_scores = np.load(f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_vuln_scoress.npy')\n",
    "except:\n",
    "    experiment.all_vuln_scores = np.array([get_vulnerability_score(experiment, experiment.X_test, experiment.y_te, experiment.original_df, index, k=4) for index in tqdm(experiment.X_test.index)])\n",
    "    np.save(f'<PATH_TO_MODEL>/{experiment.ds.ds.filenameroot}_vuln_scores.npy', experiment.all_vuln_scores)\n",
    "experiment.all_vuln_scores_rounded = np.round(experiment.all_vuln_scores)\n",
    "experiment.vuln_accuracy = accuracy_score(experiment.correct_indices, experiment.all_vuln_scores_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.all_vuln_scores_rounded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.vuln_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_w_vuln.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_w_vuln = experiment.X_test.copy()\n",
    "# X_test_w_vuln[['vuln']] \n",
    "X_test_w_vuln['vuln'] = pd.Series(experiment.all_vuln_scores_rounded, index=X_test_w_vuln.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>COW_0</th>\n",
       "      <th>COW_1</th>\n",
       "      <th>COW_2</th>\n",
       "      <th>COW_3</th>\n",
       "      <th>COW_4</th>\n",
       "      <th>COW_5</th>\n",
       "      <th>COW_6</th>\n",
       "      <th>COW_7</th>\n",
       "      <th>...</th>\n",
       "      <th>ST_42</th>\n",
       "      <th>ST_43</th>\n",
       "      <th>ST_44</th>\n",
       "      <th>ST_45</th>\n",
       "      <th>ST_46</th>\n",
       "      <th>ST_47</th>\n",
       "      <th>ST_48</th>\n",
       "      <th>ST_49</th>\n",
       "      <th>ST_50</th>\n",
       "      <th>vuln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463158</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.410526</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.231579</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AGEP      WKHP  COW_0  COW_1  COW_2  COW_3  COW_4  COW_5  COW_6   \n",
       "0      0.463158  0.393939    1.0    0.0    0.0    0.0    0.0    0.0    0.0  \\\n",
       "1      0.526316  0.393939    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "2      0.347368  0.393939    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "3      0.231579  0.797980    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4      0.178947  0.494949    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...       ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "49995  0.400000  0.545455    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49996  0.157895  0.393939    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49997  0.410526  0.393939    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "49998  0.200000  0.444444    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49999  0.231579  0.393939    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       COW_7  ...  ST_42  ST_43  ST_44  ST_45  ST_46  ST_47  ST_48  ST_49   \n",
       "0        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \\\n",
       "1        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4        0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "49995    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49996    0.0  ...    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49997    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49998    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "49999    0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ST_50  vuln  \n",
       "0        0.0   0.0  \n",
       "1        0.0   1.0  \n",
       "2        0.0   0.0  \n",
       "3        0.0   1.0  \n",
       "4        0.0   0.0  \n",
       "...      ...   ...  \n",
       "49995    0.0   0.0  \n",
       "49996    0.0   0.0  \n",
       "49997    0.0   0.0  \n",
       "49998    0.0   0.0  \n",
       "49999    0.0   0.0  \n",
       "\n",
       "[50000 rows x 108 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_w_vuln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(X_test_w_vuln.values).float(), torch.tensor(experiment.y_te_onehot).float())\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortedMLPClassifier(nn.Module):\n",
    "    def __init__(self, n_in_features=37, n_out_features=2):\n",
    "        super(PortedMLPClassifier, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(in_features=n_in_features, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=n_out_features),\n",
    "            nn.Softmax(dim=1)\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def predict_proba(self, x: torch.Tensor):\n",
    "        return self.forward(x)\n",
    "    \n",
    "class MLPClassifierMutualInfoReg(nn.Module):\n",
    "    def __init__(self, n_in_features=37, n_feat_dim=10, n_out_features=2):\n",
    "        super(MLPClassifierMutualInfoReg, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(in_features=n_in_features, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=16, out_features=8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=8, out_features=n_feat_dim),\n",
    "            # nn.Softmax(dim=1)\n",
    "        ]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.k = n_feat_dim//2\n",
    "        self.st_layer = nn.Linear(in_features=n_feat_dim, out_features=self.k*2)\n",
    "        self.classifier = nn.Linear(in_features=self.k, out_features=n_out_features)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        statis = self.st_layer(x)\n",
    "        mu, std = statis[:, :self.k], statis[:, self.k:]\n",
    "        std = torch.functional.F.softplus(std-5)\n",
    "        eps = torch.FloatTensor(std.size()).normal_().to(x.device)\n",
    "        x = mu + eps * std\n",
    "        x = self.classifier(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, mu, std\n",
    "    \n",
    "    def predict_proba(self, x: torch.Tensor):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.83s/it]\n"
     ]
    }
   ],
   "source": [
    "betas = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for beta in betas[2:3]:\n",
    "    model_zero = MLPClassifierMutualInfoReg(n_in_features=experiment.X_train.shape[1], n_feat_dim=10, n_out_features=experiment.y_tr_onehot.shape[1]).to('mps')\n",
    "    optimizer = torch.optim.Adam(model_zero.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in tqdm(range(10)):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            model_zero.train()\n",
    "            optimizer.zero_grad()\n",
    "            data, target = data.to('mps'), target.to('mps')\n",
    "            output, mu, std = model_zero(data[:, :-1])\n",
    "            info_loss = - 0.5 * (1 + 2 * (std+1e-7).log() - mu.pow(2) - std.pow(2)).sum(dim=1)\n",
    "            info_loss = info_loss\n",
    "            info_loss = info_loss.mean()\n",
    "            loss = nn.BCELoss()(output, target) + beta * info_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.85s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     22\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mmodels\u001b[49m[beta] \u001b[38;5;241m=\u001b[39m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "betas = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for beta in betas[2:3]:\n",
    "    try:\n",
    "        model = MLPClassifierMutualInfoReg(n_in_features=experiment.X_train.shape[1], n_feat_dim=10, n_out_features=experiment.y_tr_onehot.shape[1]).to('mps')\n",
    "        model.load_state_dict(torch.load(f\"mutual_info_reg_vuln_census_{beta}.pt\"))\n",
    "    except:\n",
    "        model = MLPClassifierMutualInfoReg(n_in_features=experiment.X_train.shape[1], n_feat_dim=10, n_out_features=experiment.y_tr_onehot.shape[1]).to('mps')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in tqdm(range(10)):\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                data, target = data.to('mps'), target.to('mps')\n",
    "                output, mu, std = model(data[:, :-1])\n",
    "                info_loss = - 0.5 * (1 + 2 * (std+1e-7).log() - mu.pow(2) - std.pow(2)).sum(dim=1)\n",
    "                info_loss = info_loss * data[:, -1]\n",
    "                info_loss = info_loss.mean()\n",
    "                loss = nn.BCELoss()(output, target) + beta * info_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    models[beta] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on test set\n",
    "def test_mir(model, X_test, y_te_onehot):\n",
    "    x_te = X_test.values\n",
    "    dataset = torch.utils.data.TensorDataset(torch.tensor(x_te).float(), torch.tensor(y_te_onehot).float())\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to('mps'), target.to('mps')\n",
    "        output, _, _ = model(data)\n",
    "        y_pred.append(output.cpu().detach().numpy())\n",
    "        y_true.append(target.cpu().detach().numpy())\n",
    "\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSMIA_attack_mir(model, X_test, y_test, meta, sensitive_columns=['marital_Married', 'marital_Single']):\n",
    "    dfs = [X_test.copy() for _ in range(len(meta[\"sensitive_values\"]))]\n",
    "    if sensitive_columns is None:\n",
    "        sensitive_columns = [f'{meta[\"sensitive_column\"]}_{i}' for i in range(len(meta[\"sensitive_values\"]))]\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i][sensitive_columns] = 0\n",
    "        dfs[i][sensitive_columns[i]] = 1\n",
    "\n",
    "        dfs[i] = torch.tensor(dfs[i].values).float().to('mps')\n",
    "    \n",
    "    y_confs = np.array([np.max(model.predict_proba(df).cpu().detach().numpy(), axis=1) for df in dfs]).T\n",
    "    y_preds = [np.argmax(model.predict_proba(df).cpu().detach().numpy(), axis=1)==y_test.ravel() for df in dfs]\n",
    "    y_preds = np.array(y_preds).T\n",
    "    case_1_indices = (y_preds.sum(axis=1) == 1)\n",
    "    case_2_indices = (y_preds.sum(axis=1) > 1)\n",
    "    case_3_indices = (y_preds.sum(axis=1) == 0)\n",
    "\n",
    "    eq_conf_indices = np.argwhere(y_confs[:, 0] == y_confs[:, 1]).ravel()\n",
    "    # randomly add eps to one of the confidences for the records with equal confidences\n",
    "    y_confs[eq_conf_indices, np.random.randint(0, 2, len(eq_conf_indices))] += 1e-6\n",
    "\n",
    "    sens_pred = np.zeros(y_preds.shape[0])\n",
    "    sens_pred[case_1_indices] = np.argmax(y_preds[case_1_indices], axis=1)\n",
    "    sens_pred[case_2_indices] = np.argmax(y_confs[case_2_indices], axis=1)\n",
    "    sens_pred[case_3_indices] = np.argmin(y_confs[case_3_indices], axis=1)\n",
    "    return sens_pred, {1: case_1_indices, 2: case_2_indices, 3: case_3_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CSMIA_case_by_case_results_mir(clf, X_train, y_tr, ds, subgroup_col_name, metric='precision', sensitive_col_name='marital_Single'):\n",
    "    if sensitive_col_name is None:\n",
    "        sensitive_col_name = f'{ds.ds.meta[\"sensitive_column\"]}_1'\n",
    "        sens_pred, case_indices = CSMIA_attack_mir(clf, X_train, y_tr, ds.ds.meta, sensitive_columns=None)\n",
    "    else:\n",
    "        sens_pred, case_indices = CSMIA_attack_mir(clf, X_train, y_tr, ds.ds.meta)\n",
    "    correct_indices = (sens_pred == X_train[[sensitive_col_name]].to_numpy().ravel())\n",
    "\n",
    "    # subgroup_csmia_case_dict = {\n",
    "    #     i: X_train.iloc[np.argwhere(case_indices[i]).ravel()][f'{subgroup_col_name}_1'].value_counts() for i in range(1, 4)\n",
    "    # }\n",
    "\n",
    "    subgroup_csmia_case_indices_by_subgroup_dict = {\n",
    "        i: { j: np.intersect1d(np.argwhere(case_indices[i]).ravel(), np.argwhere(X_train[f'{subgroup_col_name}'].to_numpy().ravel() == j).ravel()) for j in [1, 0] } for i in range(1, 4)\n",
    "    }\n",
    "\n",
    "    subgroup_csmia_case_indices_by_subgroup_dict['All Cases'] = { j: np.argwhere(X_train[f'{subgroup_col_name}'].to_numpy().ravel() == j).ravel() for j in [1, 0] }\n",
    "\n",
    "    def fun(metric):\n",
    "        if metric.__name__ in ['precision_score', 'recall_score', 'f1_score']:\n",
    "            return lambda x: round(100 * metric(x[0], x[1], pos_label=1), 4)\n",
    "        else:\n",
    "            return lambda x: round(100 * metric(x[0], x[1]), 4)\n",
    "    \n",
    "    def fun2(x):\n",
    "        tp, fn, fp, tn = confusion_matrix(x[0], x[1]).ravel()\n",
    "        return f\"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}\"\n",
    "    \n",
    "    def false_positive_rate(x):\n",
    "        tp, fn, fp, tn = confusion_matrix(x[0], x[1]).ravel()\n",
    "        return round(100 * fp / (fp + tn), 4)\n",
    "\n",
    "    eval_func = { \n",
    "        'precision': fun(precision_score),\n",
    "        'recall': fun(recall_score),\n",
    "        'f1': fun(f1_score),\n",
    "        'accuracy': fun(accuracy_score),\n",
    "        'fpr': false_positive_rate,\n",
    "        # 'confusion_matrix': lambda x: f\"TP: {confusion_matrix(x[0], x[1], labels=labels)[0, 0]}, FP: {confusion_matrix(x[0], x[1], labels=labels)[0, 1]}, FN: {confusion_matrix(x[0], x[1], labels=labels)[1, 0]}, TN: {confusion_matrix(x[0], x[1], labels=labels)[1, 1]}\",\n",
    "        'confusion_matrix': fun2,\n",
    "        # 'mcc': fun(matthews_corrcoef),\n",
    "        # 'gmean': fun(geometric_mean_score),\n",
    "    }[metric]\n",
    "\n",
    "    perf_dict = {\n",
    "        i: { j: eval_func((X_train.loc[subgroup_csmia_case_indices_by_subgroup_dict[i][j], sensitive_col_name], sens_pred[subgroup_csmia_case_indices_by_subgroup_dict[i][j]])) for j in [1, 0] } for i in [1, 2, 3, 'All Cases']\n",
    "    }\n",
    "\n",
    "    temp_dict = {\n",
    "        f'Case {i}': { j: f'{subgroup_csmia_case_indices_by_subgroup_dict[i][j].shape[0]} ({perf_dict[i][j]})' for j in [1, 0] } for i in [1, 2, 3, 'All Cases']\n",
    "    }\n",
    "\n",
    "    # subgroup_csmia_case_correct_dict = {\n",
    "    #     i: X_train.iloc[np.intersect1d(np.argwhere(case_indices[i]).ravel(), np.argwhere(correct_indices).ravel())][f'{subgroup_col_name}_1'].value_counts() for i in range(1, 4)\n",
    "    # }\n",
    "\n",
    "    # temp_dict = {\n",
    "    #     f'Case {i}': { j: f'{subgroup_csmia_case_dict[i][j]} ({round(100 * subgroup_csmia_case_correct_dict[i][j] / subgroup_csmia_case_dict[i][j], 2)})' for j in [1, 0] } for i in range(1, 4)\n",
    "    # }\n",
    "    # temp_dict['All Cases'] = { j: f'{subgroup_csmia_case_dict[1][j] + subgroup_csmia_case_dict[2][j] + subgroup_csmia_case_dict[3][j]} ({round(100 * (subgroup_csmia_case_correct_dict[1][j] + subgroup_csmia_case_correct_dict[2][j] + subgroup_csmia_case_correct_dict[3][j]) / (subgroup_csmia_case_dict[1][j] + subgroup_csmia_case_dict[2][j] + subgroup_csmia_case_dict[3][j]), 2)})' for j in [1, 0] }\n",
    "\n",
    "    temp_df = pd.DataFrame.from_dict(temp_dict, orient='index')\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74     25000\n",
      "           1       0.74      0.72      0.73     25000\n",
      "\n",
      "    accuracy                           0.74     50000\n",
      "   macro avg       0.74      0.74      0.74     50000\n",
      "weighted avg       0.74      0.74      0.74     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_mir(model_zero, experiment.X_train, experiment.y_tr_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.74     25000\n",
      "           1       0.73      0.80      0.76     25000\n",
      "\n",
      "    accuracy                           0.75     50000\n",
      "   macro avg       0.75      0.75      0.75     50000\n",
      "weighted avg       0.75      0.75      0.75     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_mir(model, experiment.X_train, experiment.y_tr_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case 1</th>\n",
       "      <td>4528 (70.0309)</td>\n",
       "      <td>4312 (69.2022)</td>\n",
       "      <td>69.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case 2</th>\n",
       "      <td>17836 (68.2048)</td>\n",
       "      <td>17694 (68.8312)</td>\n",
       "      <td>68.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case 3</th>\n",
       "      <td>2636 (63.7709)</td>\n",
       "      <td>2994 (58.016)</td>\n",
       "      <td>60.7105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case All Cases</th>\n",
       "      <td>25000 (68.068)</td>\n",
       "      <td>25000 (67.6)</td>\n",
       "      <td>67.8340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1                0  Overall\n",
       "Case 1           4528 (70.0309)   4312 (69.2022)  69.6267\n",
       "Case 2          17836 (68.2048)  17694 (68.8312)  68.5167\n",
       "Case 3           2636 (63.7709)    2994 (58.016)  60.7105\n",
       "Case All Cases   25000 (68.068)     25000 (67.6)  67.8340"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_CSMIA_case_by_case_results(experiment.clf_only_on_test, experiment.X_test, experiment.y_te, experiment.ds, 'SEX', metric='accuracy', sensitive_col_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case 1</th>\n",
       "      <td>5442 (66.0051)</td>\n",
       "      <td>5358 (63.3072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case 2</th>\n",
       "      <td>16512 (61.0283)</td>\n",
       "      <td>16146 (60.8572)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case 3</th>\n",
       "      <td>3046 (56.172)</td>\n",
       "      <td>3496 (52.4027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case All Cases</th>\n",
       "      <td>25000 (61.52)</td>\n",
       "      <td>25000 (60.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              1                0\n",
       "Case 1           5442 (66.0051)   5358 (63.3072)\n",
       "Case 2          16512 (61.0283)  16146 (60.8572)\n",
       "Case 3            3046 (56.172)   3496 (52.4027)\n",
       "Case All Cases    25000 (61.52)     25000 (60.2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_CSMIA_case_by_case_results_mir(model, experiment.X_test, experiment.y_te, experiment.ds, 'SEX_1', metric='accuracy', sensitive_col_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_CSMIA_case_by_case_results_mir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_CSMIA_case_by_case_results_mir\u001b[49m(model_zero, experiment\u001b[38;5;241m.\u001b[39mX_test, experiment\u001b[38;5;241m.\u001b[39my_te, experiment\u001b[38;5;241m.\u001b[39mds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSEX_1\u001b[39m\u001b[38;5;124m'\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, sensitive_col_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_CSMIA_case_by_case_results_mir' is not defined"
     ]
    }
   ],
   "source": [
    "get_CSMIA_case_by_case_results_mir(model_zero, experiment.X_test, experiment.y_te, experiment.ds, 'SEX_1', metric='accuracy', sensitive_col_name=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabular",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
