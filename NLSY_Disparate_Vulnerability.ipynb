{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cbXX9d1GS03",
        "outputId": "cf5a0fc5-1a07-4ac3-d112-9b0494da7c5c"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ehsanul9511/black-boxMIAI.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrXcPKRCKiQG",
        "outputId": "d4b992c6-36a1-4491-c51b-bdfb1f980e3c"
      },
      "outputs": [],
      "source": [
        "%cd black-boxMIAI/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9VJfFpXQOsX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7LDVJomSj81"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwsuc3_e0m_P"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKPu4tdLBdS0"
      },
      "outputs": [],
      "source": [
        "dataset = 'NLSY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyQ6FGgLHVYo"
      },
      "outputs": [],
      "source": [
        "nlsy_data_dict = {\n",
        "    'name': \"NLSY\",\n",
        "    'path': 'data/nlsy_5096.csv',\n",
        "    'dummy_columns': ['marital8', 'gender', 'race', 'arrestsdli8', 'drug_marijuana',\n",
        "        'smoking8', 'drinking8', 'sexdrugsdli8', 'sexstrng8'],\n",
        "    'numeric_columns': ['age','children', 'incarceration', 'income8'],\n",
        "    'y_column': 'ratelife8',\n",
        "    'sensitive_column': 'drug_marijuana',\n",
        "    'sensitive_pos': 'dm_yes',\n",
        "    'y_pos': \"excellent\",\n",
        "    'attack_type': \"Random\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaNqnlhwsS-M"
      },
      "outputs": [],
      "source": [
        "adult_data_dict = {\n",
        "    'name': \"Adult\",\n",
        "    'path': 'data/Adult_35222.csv',\n",
        "    'dummy_columns': [\"work\", \"education\", \"marital\", \"occupation\", \"race\", \"sex\"],\n",
        "    'numeric_columns': [\"fnlwgt\", \"capitalgain\", \"capitalloss\", \"hoursperweek\"],\n",
        "    'y_column': 'income',\n",
        "    'sensitive_column': 'marital',\n",
        "    'sensitive_pos': 'Married',\n",
        "    'y_pos': \">50K\",\n",
        "    'attack_type': \"Random\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZTuW4Wss52-"
      },
      "outputs": [],
      "source": [
        "gss_data_dict = {\n",
        "    'name': \"GSS\",\n",
        "    'path': 'data/GSS_15235.csv',\n",
        "    'dummy_columns': ['year', 'marital', 'divorce', 'sex', 'race', 'relig', 'xmovie', 'pornlaw'],\n",
        "    'numeric_columns': ['childs', 'age', 'educ'],\n",
        "    'y_column': 'hapmar',\n",
        "    'sensitive_column': 'xmovie',\n",
        "    'sensitive_pos': 'x_yes',\n",
        "    'y_pos': 'nottoohappy',\n",
        "    \"attack_type\": \"Random\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjzj0PvTBbQK"
      },
      "outputs": [],
      "source": [
        "all_data_dict = {\n",
        "    \"Adult\": adult_data_dict,\n",
        "    \"GSS\": gss_data_dict,\n",
        "    \"NLSY\": nlsy_data_dict\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJuJAL-wBnD4"
      },
      "outputs": [],
      "source": [
        "data_dict = all_data_dict[dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M05Xpw6RN-Z7"
      },
      "outputs": [],
      "source": [
        "#data = adult_data.data\n",
        "orig_data = pd.read_csv(data_dict['path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg1AolA4VFah"
      },
      "outputs": [],
      "source": [
        "if data_dict['name'] == 'GSS':\n",
        "    orig_data['pornlaw'] = orig_data['pornlaw'].replace({\"illegalillegal8\": \"illegal\"})\n",
        "elif data_dict['name'] == 'NLSY':\n",
        "    orig_data = orig_data.drop(['id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AamIGUmu9HSq"
      },
      "outputs": [],
      "source": [
        "data = orig_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "4k1_uG_BIEaJ",
        "outputId": "7eb7068a-88e6-4c8c-b35c-ef3d4eb389c2"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkBwO1KsP3X0",
        "outputId": "275db65d-a9d9-4dc8-b53c-90503eda1ff6"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDLKY3RcKzms",
        "outputId": "8cd62de0-caa6-4e30-9daf-38c356194e1e"
      },
      "outputs": [],
      "source": [
        "data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeSl0Of0zr4R"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()\n",
        "data = pd.get_dummies(data, columns=data_dict['dummy_columns'])\n",
        "numerical_features = data_dict['numeric_columns']\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(data[numerical_features])\n",
        "data[numerical_features] = scaler.transform(data[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8O-BtcxKJZj"
      },
      "outputs": [],
      "source": [
        "def draw_plot(result_df, name, flip_column_different=False, metric=\"accuracy\"):\n",
        "    if flip_column_different:\n",
        "        vals = result_df.copy()\n",
        "        vals.index = vals['Subgroup Name'].values\n",
        "        vals = vals.drop(['Subgroup Name', 'Count'], axis=1)\n",
        "        vals = vals.transpose()\n",
        "        rownames = vals.index.values\n",
        "    else:\n",
        "        rownames = result_df['Subgroup Name'].values\n",
        "        vals = result_df.drop(['Subgroup Name', 'Count'], axis=1)\n",
        "\n",
        "    x = np.arange(len(rownames))  # convert range to numpy array\n",
        "    width = len(x) \n",
        "    multiplier = 0\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 4),layout='constrained')\n",
        "\n",
        "    tick_locations = []\n",
        "\n",
        "    for attribute, measurement in vals.items():\n",
        "        # print(measurement)\n",
        "        offset = width * 2 * multiplier\n",
        "        # print(x *10 + offset)\n",
        "        loc = x * width * 2 + offset\n",
        "        tick_locations += loc.tolist()\n",
        "        rects = ax.bar(x * width * 2 + offset, measurement, width, label=attribute)\n",
        "        # print(rects)\n",
        "        ax.bar_label(rects, labels=[f\"{round(h, 2)}\" for h in measurement], padding=3)\n",
        "        multiplier += width * 1.25\n",
        "        if multiplier == 1:\n",
        "            break\n",
        "\n",
        "    ax.set_ylabel(f'ASR {metric}')\n",
        "    ax.set_title(f'Disparate Vulnerability {name}')\n",
        "    ax.set_xticks(tick_locations, rownames.tolist() * vals.shape[1], rotation=90)  # add half width to center the ticks\n",
        "    if flip_column_different:\n",
        "        ax.legend(loc='upper left', ncol=3, bbox_to_anchor=(0, 2))\n",
        "    else:\n",
        "        ax.legend(loc='upper left', ncol=3, bbox_to_anchor=(0, 1.5))\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5SWlLQJS2T9"
      },
      "outputs": [],
      "source": [
        "def get_random_data(num, one_hot_columns, orig_data):\n",
        "    orig_columns = orig_data.columns\n",
        "    unique_val_dict = {}\n",
        "    for col in orig_columns:\n",
        "        unique_val_dict[col] = orig_data[col].unique()\n",
        "        if col not in data_dict['dummy_columns'] and col != data_dict['y_column']:\n",
        "            unique_val_dict[col] = [np.min(unique_val_dict[col]), np.max(unique_val_dict[col])]\n",
        "    # print(unique_val_dict)\n",
        "    x = {}\n",
        "    for col in orig_columns:\n",
        "        if col in data_dict['dummy_columns'] or col == data_dict['y_column']:\n",
        "            # print()\n",
        "            np.random.seed(42)\n",
        "            x[col] = np.random.choice(unique_val_dict[col].tolist(), num, replace=True)\n",
        "        else:\n",
        "            np.random.seed(42)\n",
        "            # print(unique_val_dict[col][0], unique_val_dict[col][1])\n",
        "            # x[col] = [random.randint(unique_val_dict[col][0], unique_val_dict[col][1])] * 2\n",
        "            x[col] = np.random.randint(unique_val_dict[col][0], unique_val_dict[col][1], size=num)\n",
        "            # x[col] = 0\n",
        "\n",
        "    # x = pd.DataFrame([x], columns = orig_data.columns)\n",
        "    x = pd.DataFrame.from_dict(x)\n",
        "    # print(x)\n",
        "    xp = x.copy()\n",
        "    x = pd.get_dummies(x, columns=data_dict['dummy_columns'])\n",
        "    x = pd.DataFrame(x, columns=one_hot_columns)\n",
        "    x.fillna(0, inplace=True)\n",
        "    numerical_features = data_dict['numeric_columns']\n",
        "    x[numerical_features] = scaler.transform(x[numerical_features])\n",
        "\n",
        "    return x, xp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbJiBfs_OaSU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop(data_dict['y_column'], axis=1)\n",
        "y = data[data_dict['y_column']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "WjATNKnsOzCa",
        "outputId": "f56f7d8e-9bfc-4961-c6ee-6a41f8c3ffca"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create an instance of MLPClassifier with random_state set to 42\n",
        "# clf = MLPClassifier(random_state=42, hidden_layer_sizes=(30, 10, 2))\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# clf = RandomForestClassifier()\n",
        "# clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdT1GcgcRel7",
        "outputId": "8f50cad6-4ce6-4c26-f51e-f3cee58a2c5f"
      },
      "outputs": [],
      "source": [
        "score = clf.score(X_test, y_test)\n",
        "print(\"Accuracy:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_Yy6nhlVG2U"
      },
      "outputs": [],
      "source": [
        "# Assuming clf is the trained decision tree classifier\n",
        "predicted_labels = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIjxDB3xlpqH"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifD_z74Pvlm9"
      },
      "outputs": [],
      "source": [
        "sensitive_attr = data_dict['sensitive_column']\n",
        "sensitive_columns = list(filter(lambda x: sensitive_attr in x, data.columns))\n",
        "attr_len = len(sensitive_attr) + 1\n",
        "sensitive_values = [val[attr_len:] for val in sensitive_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsC-mo8WrJ44"
      },
      "outputs": [],
      "source": [
        "# random_oh_df, random_df = get_random_data(10000, data.columns, orig_data)\n",
        "# for _ in range(1):\n",
        "#     clf.predict([random_oh_df.drop(data_dict['y_column'], axis=1).iloc[0].copy()]* 100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAZtW8Lpss-I"
      },
      "outputs": [],
      "source": [
        "# Random Attack\n",
        "\n",
        "random_oh_df, random_df = get_random_data(20000, data.columns, orig_data)\n",
        "X_random = random_oh_df.drop(data_dict['y_column'], axis=1)\n",
        "default_cols = X_random.columns\n",
        "# y = random_oh_df[data_dict['y_column']]\n",
        "\n",
        "prediction_columns = []\n",
        "for sensitive_value in sensitive_values:\n",
        "    X_random[sensitive_attr + \"_\" + sensitive_value] = pd.Series(np.ones(X_random.shape[0]), index=X_random.index)\n",
        "    for other_value in sensitive_values:\n",
        "        if other_value != sensitive_value:\n",
        "            X_random[sensitive_attr + \"_\" + other_value] = pd.Series(np.zeros(X_random.shape[0]), index=X_random.index)\n",
        "\n",
        "    newcolname = \"prediction_\" + sensitive_value\n",
        "    prediction_columns.append(newcolname)\n",
        "    X_random[newcolname] = pd.Series(clf.predict(X_random[default_cols]), index=X_random.index)\n",
        "    X_random[\"confidence_\" + sensitive_value] = pd.Series(np.max(clf.predict_proba(X_random[default_cols]), axis=1), \n",
        "                                                         index=X_random.index)\n",
        "\n",
        "X_random['all_predictions'] = X_random[prediction_columns].apply(pd.Series.unique, axis=1)\n",
        "\n",
        "# X_random = X_random[X_random['all_predictions'].apply(lambda x: len(x)==len(sensitive_values))]\n",
        "\n",
        "new_df = None\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for sensitive_value in sensitive_values:\n",
        "    X_temp = X_random[default_cols].copy()\n",
        "\n",
        "    X_temp[sensitive_attr + \"_\" + sensitive_value] = pd.Series(np.ones(X_temp.shape[0]), index=X_random.index)\n",
        "    for other_value in sensitive_values:\n",
        "        if other_value != sensitive_value:\n",
        "            X_temp[sensitive_attr + \"_\" + other_value] = pd.Series(np.zeros(X_temp.shape[0]), index=X_random.index)\n",
        "\n",
        "    X_temp[data_dict['y_column']] = X_random[\"prediction_\" + sensitive_value]\n",
        "    X_temp['confidence'] = X_random[\"confidence_\" + sensitive_value]\n",
        "\n",
        "    dfs.append(X_temp.copy())\n",
        "\n",
        "random_oh_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "new_df = random_oh_df.copy()\n",
        "\n",
        "random_oh_df = random_oh_df[random_oh_df['confidence'].apply(lambda x: x > 0.8)].drop('confidence', axis=1)\n",
        "# X_test = random_oh_df.drop(data_dict['y_column'], axis=1)\n",
        "# y_test = random_oh_df[data_dict['y_column']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "pG3XLHEg7_bV",
        "outputId": "fd2cd761-fe57-4a6f-f6be-b2c9fd776c67"
      },
      "outputs": [],
      "source": [
        "sns.histplot(data=new_df, x='confidence', bins=[i/10 for i in range(11)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "E_8fzZfwZzOc",
        "outputId": "8c022fb6-1fe8-4c61-ccd4-b021bfc16f89"
      },
      "outputs": [],
      "source": [
        "ax = sns.histplot(data=new_df[new_df[sensitive_attr + \"_\" + sensitive_values[0]]==1], x='confidence', bins=[i/10 for i in range(11)])\n",
        "ax.set_xlabel(f'Confidence for {sensitive_values[0]}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "flwu3XSsaexW",
        "outputId": "eb5fe69f-44a2-4d3b-e2ce-df87bac91da9"
      },
      "outputs": [],
      "source": [
        "ax = sns.histplot(data=new_df[new_df[sensitive_attr + \"_\" + sensitive_values[1]]==1], x='confidence', bins=[i/10 for i in range(11)])\n",
        "ax.set_xlabel(f'Confidence for {sensitive_values[1]}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cCjDeQfsZSA"
      },
      "outputs": [],
      "source": [
        "# # Random Attack\n",
        "\n",
        "# def get_random_query_data():\n",
        "#     random_oh_df, random_df = get_random_data(10000, data.columns, orig_data)\n",
        "#     X_random = random_oh_df.drop(data_dict['y_column'], axis=1)\n",
        "#     # y = random_oh_df[data_dict['y_column']]\n",
        "\n",
        "\n",
        "\n",
        "#     # Assuming X_test is the test set and y_test is the true labels\n",
        "#     attack_dataset = []\n",
        "#     for i in tqdm(range(len(X_random)), disable=False):\n",
        "#         # Get the predicted label and true label for this record\n",
        "#         #pred_label = predicted_labels[i]\n",
        "#         # true_label = y_test.iloc[i]\n",
        "        \n",
        "#         # Check if the predicted label matches the true label for only one possible value of the sensitive attribute\n",
        "#         num_matches = 0\n",
        "#         matched_value = None\n",
        "#         # sensitive_values = [\"Married\", \"Single\"]\n",
        "#         records = []\n",
        "#         y_preds = []\n",
        "#         # records = [record.copy() for _ in range(len(sensitive_values))]\n",
        "#         for sensitive_value in sensitive_values:\n",
        "#             record = X_random.iloc[i].copy()\n",
        "#             record[sensitive_attr + \"_\" + sensitive_value] = 1\n",
        "\n",
        "#             for other_value in sensitive_values:\n",
        "#                 if other_value != sensitive_value:\n",
        "#                     record[sensitive_attr + \"_\" + other_value] = 0\n",
        "            \n",
        "#             # print(record[['marital_Married']])\n",
        "#             y_pred = clf.predict([record])[0]\n",
        "#             # probabilities = clf.predict_proba([record])\n",
        "#             # y_pred = model.predict(record, )\n",
        "#             # print(clf.predict_proba([record]))\n",
        "#             # print(y_pred)\n",
        "#             if y_pred in y_preds:\n",
        "#                 break\n",
        "#             else:\n",
        "#                 y_preds.append(y_pred)\n",
        "#             record[data_dict['y_column']] = y_pred\n",
        "\n",
        "#             records.append(record)\n",
        "\n",
        "#         # print(y_preds)\n",
        "\n",
        "#         if len(records) != len(sensitive_values):\n",
        "#             continue\n",
        "#         else:\n",
        "#             attack_dataset += records\n",
        "\n",
        "#     random_oh_df = pd.DataFrame(attack_dataset)\n",
        "\n",
        "#     return random_oh_df\n",
        "\n",
        "\n",
        "\n",
        "# if data_dict[\"attack_type\"] == \"Random\":\n",
        "#     random_oh_df = get_random_query_data()\n",
        "\n",
        "#     X_test = random_oh_df.drop(data_dict['y_column'], axis=1)\n",
        "#     y_test = random_oh_df[data_dict['y_column']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ2CcdMVlYhv"
      },
      "outputs": [],
      "source": [
        "# pd.crosstab(random_oh_df['marital_Married'], random_oh_df['income'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTyjeyk4eRzD",
        "outputId": "0a004c9b-df0a-463c-dc35-bf153fb2028a"
      },
      "outputs": [],
      "source": [
        "random_oh_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKsCNmiNRjMV",
        "outputId": "890d75ad-e5d9-4597-c09d-7e70af69753c"
      },
      "outputs": [],
      "source": [
        "# LOMIA Attack\n",
        "\n",
        "# Assuming X_test is the test set and y_test is the true labels\n",
        "\n",
        "attack_dataset = []\n",
        "for i in tqdm(range(len(X_test))):\n",
        "    # Get the predicted label and true label for this record\n",
        "    #pred_label = predicted_labels[i]\n",
        "    true_label = y_test.iloc[i]\n",
        "    \n",
        "    # Check if the predicted label matches the true label for only one possible value of the sensitive attribute\n",
        "    num_matches = 0\n",
        "    matched_value = None\n",
        "    # sensitive_values = [\"Married\", \"Single\"]\n",
        "    for sensitive_value in sensitive_values:\n",
        "        record = X_test.iloc[i].copy()\n",
        "        record[sensitive_attr + \"_\" + sensitive_value] = 1\n",
        "\n",
        "        for other_value in sensitive_values:\n",
        "            if other_value != sensitive_value:\n",
        "                record[sensitive_attr + \"_\" + other_value] = 0\n",
        "        \n",
        "        # Check if the predicted label matches the true label for this sensitive value\n",
        "        # if clf.predict([record])[0] == true_label:\n",
        "        if clf.predict(record.to_numpy().reshape(1, -1))[0] == true_label:\n",
        "            num_matches += 1\n",
        "            matched_value = sensitive_value\n",
        "            \n",
        "    # If there is only one match, label the record with the matched value\n",
        "    if num_matches == 1:\n",
        "        record = X_test.iloc[i].copy()\n",
        "        record[sensitive_attr + \"_\" + matched_value] = 1\n",
        "\n",
        "        for other_value in sensitive_values:\n",
        "            if other_value != matched_value:\n",
        "                record[sensitive_attr + \"_\" + other_value] = 0\n",
        "        \n",
        "        # record[data_dict['y_column']] = (true_label == data_dict['y_pos'])\n",
        "        record[data_dict['y_column']] = true_label\n",
        "        attack_dataset.append(record)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTtc1OmZVeNc"
      },
      "outputs": [],
      "source": [
        "# Convert the attack dataset to a pandas DataFrame\n",
        "attack_df = pd.DataFrame(attack_dataset)\n",
        "\n",
        "unique_values = data[data_dict['y_column']].unique()\n",
        "\n",
        "# create dictionary to map string values to numeric values\n",
        "mapping_dict = {value: index for index, value in enumerate(unique_values)}\n",
        "\n",
        "attack_df[data_dict['y_column']] = attack_df[data_dict['y_column']].map(mapping_dict)\n",
        "\n",
        "# Split the DataFrame into input and output variables\n",
        "X_attack = attack_df.drop([sensitive_attr + \"_\" + val for val in sensitive_values], axis=1) \n",
        "\n",
        "# X_attack = attack_df.drop([\"marital_Married\", \"marital_Single\"], axis=1) \n",
        "# y_attack = attack_df[[\"marital_Married\"]]\n",
        "y_attack = attack_df[[sensitive_attr + \"_\" + data_dict['sensitive_pos']]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "WjzdLlaRasQ-",
        "outputId": "3a544e36-d365-474f-bef9-636fe159d4db"
      },
      "outputs": [],
      "source": [
        "# Assuming X_attack and y_attack are the attack dataset\n",
        "# attack_model = DecisionTreeClassifier()\n",
        "# attack_model = MLPClassifier()\n",
        "attack_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
        "attack_model.fit(X_attack, y_attack)\n",
        "\n",
        "# from xgboost import XGBClassifier\n",
        "\n",
        "# attack_model = XGBClassifier()\n",
        "# attack_model.fit(X_attack, y_attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2XnWYv-cWUXR",
        "outputId": "65269bb7-0507-4be8-ee8f-248c00ba1011"
      },
      "outputs": [],
      "source": [
        "if isinstance(attack_model, MLPClassifier):\n",
        "    weights = attack_model.coefs_[0]\n",
        "\n",
        "    # calculate the absolute values of the weights and sum them across all hidden units\n",
        "    abs_weights = np.abs(weights)\n",
        "    feature_importance_scores = abs_weights.sum(axis=1)\n",
        "\n",
        "    # normalize the feature importance scores\n",
        "    feature_importance_scores /= feature_importance_scores.sum()\n",
        "\n",
        "    # print the feature importance scores\n",
        "    plt.bar(range(len(feature_importance_scores)),feature_importance_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfm8vyqSQpox",
        "outputId": "6a263a71-95c3-4baf-ceab-3d1a649f7fe9"
      },
      "outputs": [],
      "source": [
        "X_attack.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-PYTth_axRq"
      },
      "outputs": [],
      "source": [
        "# Assuming X_test is the original dataset and y_test is the true sensitive attributes (if available)\n",
        "def preprocess_attack_data(data):\n",
        "    X = data.drop([sensitive_attr + \"_\" + val for val in sensitive_values], axis=1)\n",
        "    y = data[sensitive_attr + \"_\" + data_dict['sensitive_pos']]\n",
        "\n",
        "    X[data_dict['y_column']] = X[data_dict['y_column']].map(mapping_dict)\n",
        "\n",
        "    feature_order = X_attack.columns\n",
        "    X = X[feature_order]\n",
        "    missing_value_rows = X.notna().all(axis=1)\n",
        "    X = X[missing_value_rows]\n",
        "    y = y[missing_value_rows]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX_5-s9dnhtQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_attack_data_w_high_conf(data):\n",
        "    X = data.drop([data_dict['y_column']], axis=1)\n",
        "\n",
        "    columns = X.columns\n",
        "\n",
        "    data['confidence'] = pd.Series(np.max(clf.predict_proba(data[columns]), axis=1), \n",
        "                                                         index=data.index)\n",
        "    \n",
        "    data = data[data['confidence']> 0.9].drop(['confidence'], axis=1)\n",
        "\n",
        "    X = data.drop([sensitive_attr + \"_\" + val for val in sensitive_values], axis=1)\n",
        "    y = data[sensitive_attr + \"_\" + data_dict['sensitive_pos']]\n",
        "\n",
        "    X[data_dict['y_column']] = X[data_dict['y_column']].map(mapping_dict)\n",
        "\n",
        "    feature_order = X_attack.columns\n",
        "    X = X[feature_order]\n",
        "    missing_value_rows = X.notna().all(axis=1)\n",
        "    X = X[missing_value_rows]\n",
        "    y = y[missing_value_rows]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWuWK2sDzjeV"
      },
      "outputs": [],
      "source": [
        "X, y = preprocess_attack_data(data)\n",
        "# X, y = preprocess_attack_data_w_high_conf(data)\n",
        "# random_oh_df = get_random_query_data()\n",
        "# X, y = preprocess_attack_data(random_oh_df)\n",
        "# X, y = X_attack, pd.Series(np.array(y_attack).reshape(-1), index=X_attack.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og9GohhTINeO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, roc_curve, roc_auc_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYN3XGe2T8p7"
      },
      "outputs": [],
      "source": [
        "def compare(evaluation_metric, flip_column_different, override_flip_vulnerable=None):\n",
        "\n",
        "    if data_dict['name'] == 'GSS':\n",
        "        attrs = [\"race\", \"sex\", \"pornlaw\", \"relig\"]\n",
        "    elif data_dict['name'] == 'Adult':\n",
        "        attrs = [\"race\", \"sex\", \"education\"]\n",
        "    elif data_dict['name'] == 'NLSY':\n",
        "        attrs = [\"race\", \"gender\", \"marital8\"]\n",
        "\n",
        "    result_df_dict = {}\n",
        "\n",
        "    # evaluation_metric = \"f1\"\n",
        "\n",
        "    def eval_score(y_test, y_pred):\n",
        "        if evaluation_metric == \"accuracy\":\n",
        "            return accuracy_score(y_test, y_pred)\n",
        "        elif evaluation_metric == \"f1\":\n",
        "            return f1_score(y_test, y_pred)\n",
        "        elif evaluation_metric == 'precision':\n",
        "            return precision_score(y_test, y_pred)\n",
        "        elif evaluation_metric == 'recall':\n",
        "            return recall_score(y_test, y_pred)\n",
        "        elif evaluation_metric == \"fpr\":\n",
        "            # print(y_test)\n",
        "            fpr, tpr, thresholds = roc_curve(y_test.to_numpy(), y_pred.to_numpy())\n",
        "            auc_score = roc_auc_score(y_test.to_numpy(), y_pred.to_numpy())\n",
        "            return fpr[1]  # FPR at a fixed TPR of 0.5\n",
        "\n",
        "    flip_column_different = flip_column_different\n",
        "\n",
        "    if data_dict['name'] == \"NLSY\":\n",
        "        flip_column = \"marital8\"\n",
        "        flip_vulnerable = \"nevermarried\"\n",
        "    elif data_dict['name'] == \"GSS\":\n",
        "        flip_column = \"pornlaw\"\n",
        "        flip_vulnerable = \"legal\"\n",
        "\n",
        "    if override_flip_vulnerable is not None:\n",
        "        flip_vulnerable = override_flip_vulnerable\n",
        "\n",
        "    flip_columns = list(filter(lambda x: flip_column in x, X.columns))\n",
        "    flip_target = flip_column + \"_\" + flip_vulnerable\n",
        "\n",
        "    for attr in attrs:\n",
        "\n",
        "        # attr = \"race\"\n",
        "\n",
        "        attr_columns = list(filter(lambda x: attr in x, X.columns))\n",
        "\n",
        "        attr_column_indices = {}\n",
        "\n",
        "        for col in attr_columns:\n",
        "            attr_column_indices[col] = (X[col]==1).to_numpy()\n",
        "\n",
        "        attr_name_len = len(list(attr_column_indices.keys())[0].split(\"_\")[0]) + 1\n",
        "        rows= []\n",
        "        for col in attr_column_indices:\n",
        "            row_dict = {}\n",
        "            row_dict['Subgroup Name'] = col[attr_name_len:]\n",
        "            indices = attr_column_indices[col]\n",
        "\n",
        "            row_dict['Count'] = sum(indices)\n",
        "\n",
        "            X_subset = X[indices].copy()\n",
        "            Y_subset = y[indices].copy()\n",
        "\n",
        "            predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "            \n",
        "            correct_indices_0 = (predicted_sensitive_attributes == Y_subset).to_numpy()    \n",
        "\n",
        "            # accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "            accuracy = eval_score(Y_subset, predicted_sensitive_attributes)\n",
        "            #print(f'{col} {accuracy}')\n",
        "            row_dict['Original ASR'] = accuracy\n",
        "\n",
        "            if flip_column_different:\n",
        "                X_subset_p = X_subset.copy()\n",
        "                for col in flip_columns:\n",
        "                    if col == flip_target:\n",
        "                        X_subset_p[col] = 1\n",
        "                    else:\n",
        "                        X_subset_p[col] = 0\n",
        "\n",
        "                predicted_sensitive_attributes = attack_model.predict(X_subset_p)\n",
        "\n",
        "                # accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "                accuracy = eval_score(Y_subset, predicted_sensitive_attributes)\n",
        "                #print(f'{col} {col2} {accuracy}')\n",
        "                row_dict[f'ASR after {flip_column} flipped to {flip_vulnerable}'] = accuracy\n",
        "            else:\n",
        "                for col2 in attr_column_indices:\n",
        "                    if col2 != col or True:\n",
        "                        X_subset_p = X_subset.copy()\n",
        "                        X_subset_p[col2] = 1\n",
        "                        \n",
        "                        for col3 in attr_column_indices:\n",
        "                            if col3 != col2:\n",
        "                                X_subset_p[col3] = 0\n",
        "\n",
        "                        predicted_sensitive_attributes = attack_model.predict(X_subset_p)\n",
        "\n",
        "                        # accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "                        accuracy = eval_score(Y_subset, predicted_sensitive_attributes)\n",
        "                        #print(f'{col} {col2} {accuracy}')\n",
        "                        row_dict[f'ASR after value flipped to {col2[attr_name_len:]}'] = accuracy\n",
        "\n",
        "\n",
        "            column1 = pd.Categorical(X_subset[data_dict['y_column']])\n",
        "            column2 = pd.Categorical(Y_subset)\n",
        "            # print(pd.crosstab(column1, column2))\n",
        "\n",
        "            # row_dict['Subgroup pickmax ratio'] = pd.crosstab(column1, column2).to_numpy().max(axis=1).sum()/X_subset.shape[0]\n",
        "\n",
        "            rows.append(row_dict)\n",
        "\n",
        "        result_df = pd.DataFrame(rows)\n",
        "\n",
        "        result_df_dict[attr] = result_df\n",
        "\n",
        "    for attr in result_df_dict:\n",
        "        print(result_df_dict[attr][['Subgroup Name', 'Count']])\n",
        "        draw_plot(result_df_dict[attr], attr, flip_column_different=flip_column_different, metric=evaluation_metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compare('f1', True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz01BpqG-GPL"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "X_temp, y_temp = preprocess_attack_data(data)\n",
        "\n",
        "# explainer = shap.Explainer(attack_model, X_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDR6gC8uXkeZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# Extract the weights and biases of the MLPClassifier\n",
        "weights = attack_model.coefs_\n",
        "biases = attack_model.intercepts_\n",
        "\n",
        "# Create a Keras neural network with the same architecture as the MLPClassifier\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=X_temp.shape[1]))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Set the weights and biases of the Keras neural network to be equal to the MLPClassifier\n",
        "model.layers[0].set_weights([weights[0], biases[0]])\n",
        "model.layers[1].set_weights([weights[1], biases[1]])\n",
        "model.layers[2].set_weights([weights[2], biases[2]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "7XgBaE_pZdu6",
        "outputId": "0a55016a-d92e-440b-8059-e470bc9b19b6"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_attack, y_attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tilT9q80-Fxq"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "explainer = shap.Explainer(model, X_temp.astype('float64'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYfv2H_5Y-RA"
      },
      "outputs": [],
      "source": [
        "sample_idx = 0\n",
        "sample = X_attack.iloc[sample_idx]\n",
        "shap_values = explainer.shap_values(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmhNO8lEgnNJ"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer(X_attack)\n",
        "\n",
        "# visualize the first prediction's explanation\n",
        "# shap.plots.waterfall(shap_values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "IOjPGXc-jPM0",
        "outputId": "ddb00739-0e1b-4f2f-9a1c-7660bb03e3f2"
      },
      "outputs": [],
      "source": [
        "# shap.summary_plot(shap_values, X_attack.iloc[:,:], plot_type=\"layered_violin\", color='coolwarm')\n",
        "shap.summary_plot(shap_values, X_attack.iloc[:,:], plot_type=\"violin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LcbGKw8zhIYP",
        "outputId": "dae203e1-4b26-4f56-eb19-3a1c74f38a08"
      },
      "outputs": [],
      "source": [
        "shap.plots.waterfall(shap_values[0], max_display=X_attack.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost\n",
        "import shap\n",
        "\n",
        "# train xgboost model on diabetes data:\n",
        "X1, y1 = shap.datasets.diabetes()\n",
        "# bst = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X, label=y), 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgboost.DMatrix(X1, label=y1).get_label()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeI34xUkhXtj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISO1qjIYg9te",
        "outputId": "6ce97837-e12b-4738-eb9f-bf4687ebc0d8"
      },
      "outputs": [],
      "source": [
        "shap_values[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pwnG9Q3hOV8"
      },
      "outputs": [],
      "source": [
        "def f(X):\n",
        "    return attack_model.predict([X[:,i] for i in range(X.shape[1])]).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "rWeBsecDE-jg",
        "outputId": "c97a1434-56b7-4683-8b08-f450339804de"
      },
      "outputs": [],
      "source": [
        "explainer = shap.KernelExplainer(f, X_attack.iloc[:50,:])\n",
        "shap_values = explainer.shap_values(X_attack.iloc[299,:], nsamples=500)\n",
        "shap.force_plot(explainer.expected_value, shap_values, X_attack.iloc[299,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HU0kjLuFJxa"
      },
      "outputs": [],
      "source": [
        "X,y = shap.datasets.adult()\n",
        "X_display,y_display = shap.datasets.adult(display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "Jb2FeovJFK0-",
        "outputId": "5abc14bc-4692-4ba8-e76a-1e1ce7bc23ea"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "C67SsTxuZJfc",
        "outputId": "f0306e53-5236-4a82-ca89-b63957538f26"
      },
      "outputs": [],
      "source": [
        "shap.plots.waterfall(shap_values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "EI0r6pnZZJ_Y",
        "outputId": "55aee8a8-c052-46eb-ae4f-195a69ff48ce"
      },
      "outputs": [],
      "source": [
        "for attr in result_df_dict:\n",
        "    print(result_df_dict[attr][['Subgroup Name', 'Count']])\n",
        "    draw_plot(result_df_dict[attr], attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbxU98bN0H43"
      },
      "outputs": [],
      "source": [
        "for attr in result_df_dict:\n",
        "    print(result_df_dict[attr][['Subgroup Name', 'Count']])\n",
        "    draw_plot(result_df_dict[attr], attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJBreOB0cPbw"
      },
      "outputs": [],
      "source": [
        "for attr in result_df_dict:\n",
        "    print(result_df_dict[attr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4B__CWvROIz"
      },
      "outputs": [],
      "source": [
        "def draw_plot(result_df, name):\n",
        "    rownames = result_df['Subgroup Name'].values\n",
        "    vals = result_df.drop(['Subgroup Name', 'Count'], axis=1)\n",
        "\n",
        "    x = np.arange(len(rownames))  # convert range to numpy array\n",
        "    width = len(x) \n",
        "    multiplier = 0\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 4),layout='constrained')\n",
        "\n",
        "    tick_locations = []\n",
        "\n",
        "    for attribute, measurement in vals.items():\n",
        "        # print(measurement)\n",
        "        offset = width * 2 * multiplier\n",
        "        # print(x *10 + offset)\n",
        "        loc = x * width * 2 + offset\n",
        "        tick_locations += loc.tolist()\n",
        "        rects = ax.bar(x * width * 2 + offset, measurement, width, label=attribute)\n",
        "        # print(rects)\n",
        "        ax.bar_label(rects, labels=[f\"{round(h, 2)}\" for h in measurement], padding=3)\n",
        "        multiplier += width * 1.25\n",
        "        if multiplier == 1:\n",
        "            break\n",
        "\n",
        "    ax.set_ylabel('ASR')\n",
        "    ax.set_title(f'Disparate Vulnerability {name}')\n",
        "    ax.set_xticks(tick_locations, rownames.tolist() * vals.shape[1], rotation=90)  # add half width to center the ticks\n",
        "    ax.legend(loc='upper left', ncol=3, bbox_to_anchor=(0, 1.5))\n",
        "    ax.set_ylim(0, 1)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMbPFnxo67rn"
      },
      "outputs": [],
      "source": [
        "attack_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7J1UbzKuFTj"
      },
      "outputs": [],
      "source": [
        "for attr in result_df_dict:\n",
        "    print(result_df_dict[attr][['Subgroup Name', 'Count']])\n",
        "    draw_plot(result_df_dict[attr], attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg5WTjzls5mF"
      },
      "outputs": [],
      "source": [
        "for attr in result_df_dict:\n",
        "    draw_plot(result_df_dict[attr], attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVDG80p2hEAP"
      },
      "outputs": [],
      "source": [
        "predicted_sensitive_attributes = attack_model.predict(X)\n",
        "accuracy = sum(predicted_sensitive_attributes == y) / len(y)\n",
        "print(\"Attack model accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8otkjs2bUjkQ"
      },
      "outputs": [],
      "source": [
        "attack_success_rates = []\n",
        "\n",
        "for idx, indices in enumerate([male_indices, female_indices]):\n",
        "    X_subset = X[indices].copy()\n",
        "    Y_subset = y[indices].copy()\n",
        "\n",
        "    # X_subset['income'] = 0\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_0 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    # X_subset['income'] = 1 - X_subset['income']\n",
        "    X_subset['sex_Male'] = 1 - X_subset['sex_Male']\n",
        "    X_subset['sex_Female'] = 1 - X_subset['sex_Female']\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_1 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "    attack_success_rates.append(accuracy)\n",
        "    # print(\"Attack model accuracy:\", accuracy)\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3_8gKTkj6Bc"
      },
      "outputs": [],
      "source": [
        "male_indices = (X['sex_Male'] == 1).to_numpy()\n",
        "female_indices = (X['sex_Female'] == 1).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHQHWagYtEQw"
      },
      "outputs": [],
      "source": [
        "high_income_indices = (X['income']==1).to_numpy()\n",
        "low_income_indices = (X['income']==0).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbaYs3O3u35z"
      },
      "outputs": [],
      "source": [
        "married_indices = (y==1).to_numpy()\n",
        "single_indices = (y==0).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTme4j14vJ3l"
      },
      "outputs": [],
      "source": [
        "np.logical_and(female_indices, np.logical_or(np.logical_and(married_indices, high_income_indices), np.logical_and(single_indices, low_income_indices))).sum()/female_indices.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnzolmstvWMZ"
      },
      "outputs": [],
      "source": [
        "np.logical_and(male_indices, np.logical_or(np.logical_and(married_indices, high_income_indices), np.logical_and(single_indices, low_income_indices))).sum()/male_indices.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51jygvcLnfG6"
      },
      "outputs": [],
      "source": [
        "np.logical_and(female_indices, low_income_indices).sum()/female_indices.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmkcdZhmt_L7"
      },
      "outputs": [],
      "source": [
        "np.logical_and(male_indices, low_income_indices).sum()/male_indices.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxUIIZfYlOqM"
      },
      "outputs": [],
      "source": [
        "X[male_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5glkHTYNkW8_"
      },
      "outputs": [],
      "source": [
        "attack_success_rates = []\n",
        "\n",
        "for indices in [male_indices, female_indices]:\n",
        "    predicted_sensitive_attributes = attack_model.predict(X[indices])\n",
        "    accuracy = sum(predicted_sensitive_attributes == y[indices]) / len(y[indices])\n",
        "    attack_success_rates.append(accuracy)\n",
        "    # print(\"Attack model accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hmr8cYx2sHhY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the data\n",
        "subgroups = [\"Male\", \"Female\"]\n",
        "\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(subgroups, attack_success_rates)\n",
        "\n",
        "for i, rate in enumerate(attack_success_rates):\n",
        "    plt.text(i, rate + 0.01, f\"{rate:.2f}\", ha=\"center\")\n",
        "\n",
        "# Set the labels\n",
        "plt.xlabel(\"Subgroup\")\n",
        "plt.ylabel(\"Attack Success Rate\")\n",
        "plt.ylim(0, np.max(attack_success_rates) + 0.2)\n",
        "plt.title(\"Bar Plot of Attack Success Rates by Subgroup\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-gd66mR553m"
      },
      "outputs": [],
      "source": [
        "attack_success_rates = []\n",
        "\n",
        "for idx, indices in enumerate([male_indices, female_indices]):\n",
        "    X_subset = X[indices].copy()\n",
        "    Y_subset = y[indices].copy()\n",
        "\n",
        "    # X_subset['income'] = 0\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_0 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    # X_subset['income'] = 1 - X_subset['income']\n",
        "    X_subset['sex_Male'] = 1 - X_subset['sex_Male']\n",
        "    X_subset['sex_Female'] = 1 - X_subset['sex_Female']\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_1 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "    attack_success_rates.append(accuracy)\n",
        "    # print(\"Attack model accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d12CGnmm6KX0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the data\n",
        "subgroups = [\"Male Records\\n With Gender Flipped\\n to Female\", \"Female Records\\n With Gender Flipped\\n to Male\"]\n",
        "\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(subgroups, attack_success_rates)\n",
        "\n",
        "for i, rate in enumerate(attack_success_rates):\n",
        "    plt.text(i, rate + 0.01, f\"{rate:.2f}\", ha=\"center\")\n",
        "\n",
        "# Set the labels\n",
        "plt.xlabel(\"Subgroup\")\n",
        "plt.ylabel(\"Attack Success Rate\")\n",
        "plt.ylim(0, np.max(attack_success_rates) + 0.2)\n",
        "plt.title(\"Bar Plot of Attack Success Rates by Subgroup\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhgIWUHYl9Eh"
      },
      "outputs": [],
      "source": [
        "attack_success_rates = []\n",
        "for idx, indices in enumerate([male_indices, female_indices]):\n",
        "    X_subset = X[indices].copy()\n",
        "    Y_subset = y[indices].copy()\n",
        "\n",
        "    # X_subset['income'] = 0\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_0 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    X_subset['income'] = 1 - X_subset['income']\n",
        "    # X_subset['sex_Male'] = 1 - X_subset['sex_Male']\n",
        "    # X_subset['sex_Female'] = 1 - X_subset['sex_Female']\n",
        "    predicted_sensitive_attributes = attack_model.predict(X_subset)\n",
        "    correct_indices_1 = (predicted_sensitive_attributes == Y_subset).to_numpy()\n",
        "\n",
        "    accuracy = sum(predicted_sensitive_attributes == Y_subset) / len(Y_subset)\n",
        "    # print(\"Attack model accuracy:\", accuracy)\n",
        "    attack_success_rates.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-doilrko6pib"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the data\n",
        "subgroups = [\"Male Records\\n With Income Flipped\\n from Orig. Value\", \"Female Records\\n With Income Flipped\\n from Orig. Value\"]\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(subgroups, attack_success_rates)\n",
        "\n",
        "for i, rate in enumerate(attack_success_rates):\n",
        "    plt.text(i, rate + 0.01, f\"{rate:.2f}\", ha=\"center\")\n",
        "\n",
        "# Set the labels\n",
        "plt.xlabel(\"Subgroup\")\n",
        "plt.ylabel(\"Attack Success Rate\")\n",
        "plt.ylim(0, np.max(attack_success_rates) + 0.2)\n",
        "plt.title(\"Bar Plot of Attack Success Rates by Subgroup\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll2AYhOEooBi"
      },
      "outputs": [],
      "source": [
        "correct_indices_inverted.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGfAffqswjXT"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5boBVrZulXP"
      },
      "outputs": [],
      "source": [
        "idx = random.randInt()\n",
        "record = X.iloc[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szGcFxYswuX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZt5TZDzy15A"
      },
      "outputs": [],
      "source": [
        "for i in range(100):\n",
        "    for group in ['sex', 'race', 'work', 'occupation']:\n",
        "        idx = 52\n",
        "        print(attack_model.predict([X.loc[idx]]))\n",
        "\n",
        "        group_columns = [c for c in X.columns if c.startswith(group)]\n",
        "        max_column = np.random.choice(X[group_columns].idxmax(axis=1))\n",
        "        X.loc[idx, group_columns] = 0\n",
        "        X.loc[idx, max_column] = 1\n",
        "        print(attack_model.predict([X.loc[idx]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewlPBI5w2NVh"
      },
      "outputs": [],
      "source": [
        "print(attack_model.predict([X.loc[idx]]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
